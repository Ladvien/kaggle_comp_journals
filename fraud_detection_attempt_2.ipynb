{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import gc # handle my garbage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Load and Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4d3dadb8fd86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/input/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}test_identity.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}train_identity.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_trans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}test_transaction.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "data_path = os.getcwd() + '/input/'\n",
    "test_id = pd.read_csv(f'{data_path}test_identity.csv')\n",
    "train_id = pd.read_csv(f'{data_path}train_identity.csv')\n",
    "test_trans = pd.read_csv(f'{data_path}test_transaction.csv')\n",
    "train_trans = pd.read_csv(f'{data_path}train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_trans, train_id, how = 'left', on ='TransactionID')\n",
    "del train_id, train_trans # Remove old data\n",
    "test_df = pd.merge(test_trans, test_id, how = 'left', on ='TransactionID')\n",
    "del test_id, test_trans   # Remove old data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Feature Engineering Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_in_df(df):\n",
    "    df = pd.DataFrame(data={'missing_rate': df.isnull().sum() / len(df) * 100 }).reset_index(level = 0)\n",
    "    df.columns = ['feature', 'missing_rate']\n",
    "    df = df.sort_values(['missing_rate'], ascending = False).reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "missing_in_df(train_df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(df):\n",
    "    # Manually create list of categorical variables.\n",
    "    cat_vars = ['ProductCD', 'card1', 'card2', 'card3', 'card4','card5',\n",
    "                'card6','M1','M2','M3','M4','M5','M6','M7','M8','M9',\n",
    "                'addr1', 'addr2', 'P_emaildomain', 'R_emaildomain',\n",
    "                'DeviceType', 'DeviceInfo', 'id_12', 'id_13','id_14','id_15','id_16',\n",
    "                'id_17',  'id_18',  'id_19',  'id_20',  'id_21',  'id_22',  \n",
    "                'id_23',  'id_24',  'id_25',  'id_26',  'id_27',  'id_28',  \n",
    "                'id_29',  'id_30',  'id_31',  'id_32',  'id_33',  'id_34',  \n",
    "                'id_35',  'id_36',  'id_37',  'id_38']\n",
    "\n",
    "    keys = ['TransactionID']\n",
    "\n",
    "    targets = ['isFraud']\n",
    "\n",
    "    time_vars = ['TransactionDT']\n",
    "\n",
    "    # Everything else is continuous.\n",
    "    cont_vars = [col for col in list(df.columns.values) if col not in (cat_vars + keys + time_vars + targets)]\n",
    "    \n",
    "    return keys, targets, cat_vars, cont_vars, time_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, targets, cat_vars, cont_vars, time_vars = get_labels(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Impute missing\n",
    "Impute the most frequent values where a categorical variable is missing a value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute most frequent.\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = MissingIndicator(error_on_new = False, features = 'missing-only')\n",
    "indicator.fit(train_df)\n",
    "\n",
    "indictator_cols = [col + '_na' for col in train_df.columns[indicator.features_]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([\n",
    "        train_df.reset_index(),\n",
    "        pd.DataFrame(indicator.transform(train_df), columns = indictator_cols)\n",
    "    ],\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['isFraud'] = 0.5 # Temporary, makes transform easier.\n",
    "test_df = pd.concat([\n",
    "        test_df.reset_index(),\n",
    "        pd.DataFrame(indicator.transform(test_df), columns = indictator_cols)\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "test_df.drop('isFraud', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_imputer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'most_frequent'))\n",
    "])\n",
    "\n",
    "numeric_imputer = Pipeline(steps = [\n",
    "    ('imputer', SimpleImputer(strategy = 'mean'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [\n",
    "    ('categoric_imputer', categoric_imputer, cat_vars),\n",
    "    ('numeric_imputer', numeric_imputer, cont_vars)\n",
    "], n_jobs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_df(train_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_headers = list(train_df.columns.values)\n",
    "train_df[cat_vars + cont_vars] = pd.DataFrame(preprocessor.fit_transform(train_df[cat_vars + cont_vars]))\n",
    "train_df.columns = tmp_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_headers = list(test_df[cat_vars + cont_vars].columns.values)\n",
    "test_df[cat_vars + cont_vars] = pd.DataFrame(preprocessor.transform(test_df[cat_vars + cont_vars]))\n",
    "test_df[cat_vars + cont_vars].columns = tmp_headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_in_df(train_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.isnull().mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n",
    "\n",
    "with open('test_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 String cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open('test_df_snapshot.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, targets, cat_vars, cont_vars, time_vars = get_labels(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_unique_values(df, threshold = 'x', just_sum = False):\n",
    "    value_counts = pd.Series(df.T.apply(lambda x: x.nunique(), axis = 1))\n",
    "    value_counts = pd.DataFrame({'unique_values': value_counts}).sort_values('unique_values', ascending = False)\n",
    "    if threshold != 'x':\n",
    "        value_counts[value_counts['unique_values'] > threshold]\n",
    "    if just_sum:\n",
    "        return value_counts.sum()\n",
    "    else:\n",
    "        return value_counts\n",
    "    \n",
    "col_unique_values(train_df[cat_vars]).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_oses = ['windows', 'mac', 'linux', 'android', 'ios']\n",
    "\n",
    "def consolidate_oses(df):\n",
    "    df['id_30'] = df['id_30'].str.lower()\n",
    "    for major_os in major_oses:\n",
    "        df['id_30'] = df['id_30'].apply(lambda x: major_os if major_os in x else x)\n",
    "    return df\n",
    "\n",
    "train_df = consolidate_oses(train_df)\n",
    "test_df = consolidate_oses(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_devices = ['sm-', 'android', 'samsung', 'windows', 'lg-', 'pixel', 'htc', \n",
    "                 'lenovo', 'macos', 'moto', 'ilium', 'trident', 'rv:',\n",
    "                 'build', 'helix', 'linux', 'win', 'iphone', 'intel', 'nexus',\n",
    "                'microsoft']\n",
    "\n",
    "# 1. Convert all A-Z to a-z.\n",
    "# 2. Fill NA with 'other'\n",
    "# 3. Group by OS, dropping version information (feature degradation)\n",
    "# 4. Fill in NA or blanks with 'other'\n",
    "# 5. Relabel unclean device string to uniform for major devices.\n",
    "# 6. All non-major devices, decided by \"threshold,\" are labeled as \"other.\"\n",
    "\n",
    "threshold = 50\n",
    "\n",
    "def consolidate_odd_devices(df, threshold):\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].str.lower()\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].str.replace('\\d+', '')\n",
    "\n",
    "    for major_device in major_devices:\n",
    "        df['DeviceInfo'] = df['DeviceInfo'].apply(lambda x: major_device if major_device in x else x)\n",
    "\n",
    "    odd_devices = pd.DataFrame(df.groupby('DeviceInfo')[keys].nunique())\n",
    "    odd_devices.columns = ['count_values']\n",
    "    odd_devices = odd_devices[odd_devices['count_values'] < threshold]\n",
    "    odd_devices = odd_devices.index.values.tolist()\n",
    "\n",
    "    for odd_device in odd_devices:\n",
    "        df['DeviceInfo'] = df['DeviceInfo'].apply(lambda x: 'other' if odd_device == x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = consolidate_odd_devices(train_df, threshold)\n",
    "test_df = consolidate_odd_devices(test_df, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert all A-Z to a-z.\n",
    "# 2. Fill NA with 'other'\n",
    "# 3. Group by OS, dropping version information (feature degradation)\n",
    "# 4. Fill in NA or blanks with 'other'\n",
    "# 5. Relabel unclean device string to uniform for major devices.\n",
    "# 6. All non-major devices, decided by \"threshold,\" are labeled as \"other.\"\n",
    "\n",
    "def consolidate_screen_size(df):\n",
    "    df[['screen_width', \n",
    "          'screen_height']] = df['id_33'].str.split('x',\n",
    "                                                        n = 1,\n",
    "                                                        expand = True).astype('int16')\n",
    "    return df\n",
    "\n",
    "train_df = consolidate_screen_size(train_df)\n",
    "test_df = consolidate_screen_size(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a count of all responses\n",
    "# 2. Fill NaN with 'other'\n",
    "# 3. Group all under the threshold as 'other'\n",
    "\n",
    "threshold = 50\n",
    "\n",
    "def consolidate_browsers(df, threshold):\n",
    "    count_cat_id_31 = pd.DataFrame(df.groupby('id_31')['TransactionID'].nunique())\n",
    "    count_cat_id_31.columns = ['count']\n",
    "    count_cat_id_31.sort_values('count', ascending = False)\n",
    "    odd_browsers = count_cat_id_31[count_cat_id_31['count'] < threshold].index.values.tolist()\n",
    "    df['id_31'] = df['id_31'].apply(lambda x: 'other' if x in odd_browsers  else x)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = consolidate_browsers(train_df, threshold)\n",
    "test_df = consolidate_browsers(test_df, threshold)\n",
    "\n",
    "count_cat_id_31 = pd.DataFrame(train_df.groupby('id_31')['TransactionID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fill in na with 'other'\n",
    "# 2. Split on '.', keeping only vendor name.\n",
    "\n",
    "email_vars_split = ['P_vendor', 'P_emaildomain', 'P_emailextra']\n",
    "\n",
    "def consolidate_email_vendors(df, cols):\n",
    "    # Purchaser\n",
    "    df[cols] = df['P_emaildomain'].str.split('.',\n",
    "                                        n = 2,\n",
    "                                        expand = True)\n",
    "    \n",
    "    # Recipient\n",
    "    df[cols] = df['R_emaildomain'].str.split('.',\n",
    "                                        n = 2,\n",
    "                                        expand = True)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    \n",
    "train_df = consolidate_email_vendors(train_df, email_vars_split)\n",
    "test_df = consolidate_email_vendors(test_df, email_vars_split)\n",
    "cat_vars += email_vars_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['P_emaildomain'].fillna(0, inplace = True)\n",
    "train_df['P_emailextra'].fillna(0, inplace = True)\n",
    "test_df['P_emaildomain'].fillna(0, inplace = True)\n",
    "test_df['P_emailextra'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n",
    "\n",
    "gc.collect()\n",
    "with open('test_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 High cardinality\n",
    "\n",
    "I'm going to try using probability encoding for highly cardinal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open('test_df_snapshot.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, targets, cat_vars, cont_vars, time_vars = get_labels(train_df)\n",
    "cat_vars += ['P_vendor', 'P_emailextra']\n",
    "cont_vars += ['screen_width', 'screen_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card1    13553\n",
      "id_19      522\n",
      "card2      500\n",
      "id_21      490\n",
      "id_20      394\n",
      "id_25      341\n",
      "addr1      332\n",
      "id_33      260\n",
      "card5      119\n",
      "card3      114\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[cat_vars].nunique().sort_values(ascending = False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card1</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>7919</td>\n",
       "      <td>14932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>9500</td>\n",
       "      <td>14162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11593</th>\n",
       "      <td>15885</td>\n",
       "      <td>10361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12616</th>\n",
       "      <td>17188</td>\n",
       "      <td>10344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10950</th>\n",
       "      <td>15066</td>\n",
       "      <td>7945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card1  count\n",
       "5365    7919  14932\n",
       "6615    9500  14162\n",
       "11593  15885  10361\n",
       "12616  17188  10344\n",
       "10950  15066   7945"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['card1']).size().reset_index(name='count')\\\n",
    "                                  .sort_values('count', ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding with Probability-Ratio (93 ROC, 89 final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highly_cardinal_to_target_prob_ratio(train_df, test_df, var, target):\n",
    "    print(f'Ratio\\'ing {var}')\n",
    "    prob_df = pd.DataFrame(train_df.groupby([var])[target].mean())\n",
    "    prob_df['ratio'] = prob_df[target] / (1 - prob_df[target])\n",
    "    train_df[var] = train_df[var].map(prob_df['ratio'].to_dict())\n",
    "    test_df[var] = test_df[var].map(prob_df['ratio'].to_dict())\n",
    "\n",
    "for var in cat_vars:\n",
    "    highly_cardinal_to_target_prob_ratio(train_df, test_df, var, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After ratio encoding, some values in test_df will be left \n",
    "# nan, a result from value not in test and train.\n",
    "test_df.fillna(0.000001, inplace = True)\n",
    "test_df.isnull().mean().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n",
    "\n",
    "gc.collect()\n",
    "with open('test_df_snapshot.pkl', 'wb') as f:\n",
    "    pickle.dump(test_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this the imputation step.\n",
    "with open('train_df_snapshot.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n",
    "\n",
    "with open('test_df_snapshot.pkl', 'rb') as f:\n",
    "    test_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom helper code.\n",
    "code_folder = '/home/ladvien/bitfocus_python_tools/ml/nn_util'\n",
    "sys.path.append(code_folder)\n",
    "from nn_util import load_train_data, pile_layers, select_optimizer, confusion_matrix_printed, reduce_mem_usage, test_classification_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, targets, cat_vars, cont_vars, time_vars = get_labels(train_df)\n",
    "cat_vars += ['P_vendor', 'P_emailextra']\n",
    "cont_vars += ['screen_width', 'screen_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.isnull().mean().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('index', axis = 1, inplace = True)\n",
    "test_df.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['TransactionID', 'TransactionDT'], axis = 1, inplace = True)\n",
    "test_df.drop(['TransactionID', 'TransactionDT'], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.replace([np.inf, -np.inf], 0.000001, inplace = True)\n",
    "test_df.replace([np.inf, -np.inf], 0.000001, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['isFraud']\n",
    "train_df.drop('isFraud', axis = 1, inplace = True)\n",
    "X = train_df; del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "test_df = scaler.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, na_list = reduce_mem_usage(train_df)\n",
    "# test_df, na_list = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.4, \n",
    "                                                    random_state = 42, \n",
    "                                                    shuffle = False)\n",
    "del X; del y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state = 42, n_jobs = 12)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info = {\n",
    "\t\"dataFileName\": \"\",\n",
    "\t\"projectName\": \"fraud\",\n",
    "\t\"dependentVariable\": \"isFraud\",\n",
    "\t\"batchSize\": 128,\n",
    "    \"targetThreshold\": 0.9,\n",
    "\t\"epochs\": 1000,\n",
    "\t\"loss\": \"binary_crossentropy\",\n",
    "\t\"optimizer\": \"adam\",\n",
    "    \"last_layer_output\": 1,\n",
    "\t\"lastLayerActivator\": \"sigmoid\",\n",
    "\t\"learningRate\": 0.01,\n",
    "    \"numStepsBeforeValidation\": 2,\n",
    "\t\"hiddenLayers\": [\n",
    "\t\t    { \"type\": \"dense\", \"activation\": \"relu\", \"widthModifier\": 0.01, \"dropout\": 0.8 },\n",
    "            { \"type\": \"dense\", \"activation\": \"relu\", \"widthModifier\": 0.01, \"dropout\": 0.5 }\n",
    "    ],\n",
    "    \"colsToDrop\": [],\n",
    "    \"model_path\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.getcwd() + '/models/'\n",
    "model_name = 'model.hdf5'\n",
    "model_filepath = model_path + model_name\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "class roc_auc_callback(Callback):\n",
    "    \n",
    "    highest_roc = 0.0\n",
    "    \n",
    "    def __init__(self, training_data, validation_data, model_path, val_on):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        self.model_path = model_path\n",
    "        self.val_on = val_on\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.val_on == 0:\n",
    "    \n",
    "            try:\n",
    "                y_pred_val = self.model.predict_proba(self.x_val, verbose = 0)\n",
    "                roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "                roc_auc_val = round(roc_val, 5)\n",
    "                norm_gini_val = round((roc_val * 2 - 1), 5)\n",
    "                print(f'\\nroc_auc_val: {str(roc_auc_val)}')\n",
    "\n",
    "                if self.highest_roc < roc_auc_val:\n",
    "                    self.highest_roc = roc_auc_val\n",
    "                    print(f'\\nNew high ROC: {round(roc_auc_val * 100, 5)}%\\n')\n",
    "                    model.save(self.model_path)\n",
    "                    print(self.model_path)\n",
    "            except:\n",
    "                print('Failed ROC')\n",
    "                 \n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [roc_auc_callback(training_data = (X_train, y_train), \n",
    "                                   validation_data = (X_test, y_test), \n",
    "                                   model_path = model_filepath,\n",
    "                                   val_on = job_info['numStepsBeforeValidation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = select_optimizer(job_info['optimizer'], job_info['learningRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pile_layers(X_train.shape[1], \n",
    "                    optimizer, \n",
    "                    job_info['loss'], \n",
    "                    job_info['hiddenLayers'], \n",
    "                    job_info['lastLayerActivator'],\n",
    "                    last_layer_output = 1)\n",
    "try:\n",
    "    model.summary()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = job_info['epochs'], \n",
    "                    batch_size = job_info['batchSize'], \n",
    "                    shuffle = True,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XGBoost\n",
    "import gc\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(\n",
    "    n_estimators=600,\n",
    "    verbosity=1,\n",
    "    tree_method='gpu_hist'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test XGBoost\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_val = roc_auc_score(y_test, y_pred[:,1:2])\n",
    "print(roc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(test_df)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions.columns = ['notFraud', 'isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getcwd() + '/input/'\n",
    "submission = pd.read_csv(f'{data_path}sample_submission.csv')\n",
    "\n",
    "submission['isFraud'] = predictions['isFraud'].values\n",
    "\n",
    "submission.to_csv('/home/ladvien/Desktop/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
